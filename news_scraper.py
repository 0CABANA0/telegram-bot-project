"""
news_scraper.py - ë„¤ì´ë²„ ë‰´ìŠ¤ ìŠ¤í¬ë˜í¼
ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

import requests
from bs4 import BeautifulSoup


def scrape_naver_news(keyword: str, count: int = 5) -> list[dict]:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

    Args:
        keyword: ê²€ìƒ‰ í‚¤ì›Œë“œ
        count: ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ìˆ˜ (ê¸°ë³¸ê°’: 5)

    Returns:
        list[dict]: ë‰´ìŠ¤ ëª©ë¡ [{"title": ..., "link": ..., "summary": ...}, ...]
    """
    url = "https://search.naver.com/search.naver"
    params = {
        "where": "news",
        "query": keyword,
    }

    headers = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/120.0.0.0 Safari/537.36"
        )
    }

    try:
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")

        news_list = []
        articles = soup.select("div.news_area")[:count]

        for article in articles:
            title_tag = article.select_one("a.news_tit")
            summary_tag = article.select_one("div.news_dsc")

            if title_tag:
                news_list.append({
                    "title": title_tag.get_text(strip=True),
                    "link": title_tag.get("href", ""),
                    "summary": summary_tag.get_text(strip=True) if summary_tag else "",
                })

        return news_list
    except requests.RequestException as e:
        print(f"[ERROR] ë‰´ìŠ¤ ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨: {e}")
        return []


def format_news_for_telegram(news_list: list[dict]) -> str:
    """
    ë‰´ìŠ¤ ëª©ë¡ì„ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í˜•ì‹(HTML)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        news_list: scrape_naver_news()ì˜ ë°˜í™˜ê°’

    Returns:
        str: HTML í˜•ì‹ì˜ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€
    """
    if not news_list:
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    lines = ["ğŸ“° <b>ë„¤ì´ë²„ ë‰´ìŠ¤ ìš”ì•½</b>\n"]
    for i, news in enumerate(news_list, 1):
        lines.append(
            f'{i}. <a href="{news["link"]}">{news["title"]}</a>\n'
            f'   {news["summary"][:80]}...\n'
        )

    return "\n".join(lines)
